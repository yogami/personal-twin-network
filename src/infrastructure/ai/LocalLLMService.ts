/**
 * LocalLLMService - Wrapper for Chrome's built-in Gemini Nano (window.ai)
 * 
 * Provides "bleeding edge" on-device reasoning capabilities.
 * graceful degradation if browser compatibility is missing.
 */

import { Twin } from '@/domain/entities/Twin';

// Experimental type definitions for window.ai
declare global {
    interface Window {
        ai?: {
            canCreateTextSession(): Promise<'readily' | 'after-download' | 'no'>;
            createTextSession(options?: {
                initialPrompts?: { role: 'system' | 'user' | 'assistant'; content: string }[];
            }): Promise<AITextSession>;
            assistant?: {
                capabilities(): Promise<{ available: 'readily' | 'after-download' | 'no' }>;
                create(options?: any): Promise<AITextSession>;
            }
        };
        // Older/alternative spec (window.model)
        model?: {
            canCreateTextSession(): Promise<boolean>;
            createTextSession(): Promise<AITextSession>;
        };
    }
}

interface AITextSession {
    prompt(input: string): Promise<string>;
    promptStreaming(input: string): ReadableStream;
    destroy(): void;
}

export interface ICEBreakerResult {
    text: string;
    isLocal: boolean;
}

export class LocalLLMService {
    private session: AITextSession | null = null;
    private isAvailable: boolean | null = null;

    /**
     * Check if Gemini Nano is available in this browser
     */
    async checkAvailability(): Promise<boolean> {
        if (typeof window === 'undefined') return false;

        // Try standard window.ai
        if (window.ai) {
            try {
                // Initial spec
                if (typeof window.ai.canCreateTextSession === 'function') {
                    const status = await window.ai.canCreateTextSession();
                    return status === 'readily';
                }
                // Newer 'assistant' spec
                if (window.ai.assistant) {
                    const capabilities = await window.ai.assistant.capabilities();
                    return capabilities.available === 'readily';
                }
            } catch (e) {
                console.warn('Error checking window.ai:', e);
            }
        }

        return false;
    }

    /**
     * Initialize a session specifically for networking advice
     */
    async initialize(): Promise<boolean> {
        if (this.session) return true;

        const available = await this.checkAvailability();
        if (!available) return false;

        try {
            const systemPrompt = "You are a helpful networking assistant residing on the user's device. Your goal is to help them connect with others at a tech conference. Be concise, professional, and friendly.";

            if (window.ai?.assistant) {
                this.session = await window.ai.assistant.create({
                    systemPrompt
                });
            } else if (window.ai) {
                this.session = await window.ai.createTextSession({
                    initialPrompts: [{ role: 'system', content: systemPrompt }]
                });
            }
            return true;
        } catch (e) {
            console.error('Failed to initialize local LLM:', e);
            return false;
        }
    }

    /**
     * Generate an icebreaker for a match locally
     */
    async generateIcebreaker(
        myTwin: Twin,
        theirTwin: Twin
    ): Promise<string> {
        if (!this.session) {
            const success = await this.initialize();
            if (!success) {
                return "Ask them: 'What brings you to the Berlin AI Conference?' (Generated by fallback, enable Chrome AI for custom icebreakers!)";
            }
        }

        const prompt = `
            Me: ${myTwin.publicProfile.headline}. Interests: ${myTwin.publicProfile.interests.join(', ')}.
            Them: ${theirTwin.publicProfile.name}, ${theirTwin.publicProfile.headline}. Interests: ${theirTwin.publicProfile.interests.join(', ')}.
            
            Suggest 2 short, specific conversational icebreakers to start a chat with them. Focus on shared interests if any.
        `;

        try {
            const response = await this.session!.prompt(prompt);
            return response.trim();
        } catch (e) {
            console.error('Local LLM generation failed:', e);
            return "Hi there! I saw we both have similar interests. How are you enjoying the conference?";
        }
    }

    /**
     * Explain why two twins matched
     */
    async explainMatch(
        myTwin: Twin,
        theirTwin: Twin,
        score: number
    ): Promise<string> {
        if (!this.session) {
            const success = await this.initialize();
            if (!success) return "High similarity in professional interests and skills.";
        }

        const prompt = `
            Compare these two profiles (Match Score: ${score}%):
            
            Profile A: ${myTwin.publicProfile.headline}, Skills: ${myTwin.publicProfile.skills.join(', ')}.
            Profile B: ${theirTwin.publicProfile.headline}, Skills: ${theirTwin.publicProfile.skills.join(', ')}.
            
            Explain in 1 sentence why they are a good professional match.
        `;

        try {
            return await this.session!.prompt(prompt);
        } catch (e) {
            return "You share complementary skills and interests.";
        }
    }

    isSupported(): boolean {
        return typeof window !== 'undefined' && !!(window.ai);
    }
}

// Singleton
export const localLLM = new LocalLLMService();
